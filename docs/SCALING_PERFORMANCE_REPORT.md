# 분산 LLM 스케일링 성능 측정 보고서

## 개요

본 문서는 dllama 분산 추론 시스템의 워커 노드 수에 따른 성능 측정 결과를 정리한 보고서입니다.

**테스트 환경:**
- 모델: `dllama_model_llama-30b_q40.m`
- 토크나이저: `dllama_tokenizer_llama2.t`
- 버퍼 타입: `q80`
- 프롬프트: "Hello world"
- 최대 스텝: 128
- 스레드 수: 4

## 측정 결과 요약

| 워커 수 | Root 메모리 | Worker 메모리 | Tokens/s | TPOT (ms) | TTFT (s) | RCT (s) |
|---------|-------------|---------------|----------|-----------|----------|---------|
| 2대     | 12 GB       | 1 GB          | 0.39     | 2423.55   | 16.002   | 309.349 |
| 4대     | 6.7 GB      | 5.9 GB        | 0.44     | 2150.56   | 16.082   | 275.581 |
| 8대     | 3.8 GB      | 3.0 GB        | 0.18     | 5368.63   | 37.767   | 687.061 |

**주요 지표 설명:**
- **Tokens/s**: 초당 생성 토큰 수
- **TPOT**: Time Per Output Token (출력 토큰당 시간, 밀리초)
- **TTFT**: Time To First Token (첫 토큰까지의 시간, 초)
- **RCT**: Request Completion Time (요청 완료 시간, 초)

## 상세 측정 결과

### 1. 2대 워커 구성

**메모리 사용량:**
- Root: 12 GB
- Worker: 1 GB

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.44 (2278.38 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.41 (2421.65 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.39
- TPOT_MS: 2423.55
- TTFT_S: 16.002
- RCT_S: 309.349

**네트워크 성능:**
- 총 작업 수: 77,952
- 총 전송량: 1,227.59 MB
- 평균 지연시간: 3.66 ms
- 최대 지연시간: 228.62 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 14.19 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 3.66 ms)
- P50: 0.01ms, P95: 9.01ms, P99: 11.52ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 382 ops, 30.92 MB, 2.01 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.49 ms avg
- readMany: 94 ops, 0.63 MB, 7.75 ms avg

---

### 2. 4대 워커 구성

**메모리 사용량:**
- Root: 6,739 MB (약 6.7 GB)
- Worker: 5,926 MB (약 5.9 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.45 (2201.39 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.47 (2148.05 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.44
- TPOT_MS: 2150.56
- TTFT_S: 16.082
- RCT_S: 275.581

**네트워크 성능:**
- 총 작업 수: 108,928
- 총 전송량: 2,461.67 MB
- 평균 지연시간: 5.16 ms
- 최대 지연시간: 421.25 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 80.43 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 5.16 ms)
- P50: 0.08ms, P95: 26.21ms, P99: 31.59ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 274 ops, 44.35 MB, 11.88 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.56 ms avg
- readMany: 202 ops, 1.36 MB, 15.72 ms avg

---

### 3. 8대 워커 구성

**메모리 사용량:**
- Root: 3,782 MB (약 3.8 GB)
- Worker: 2,970 MB (약 3.0 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.19 (5347.35 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.19 (5365.57 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.18
- TPOT_MS: 5368.63
- TTFT_S: 37.767
- RCT_S: 687.061

**네트워크 성능:**
- 총 작업 수: 170,880
- 총 전송량: 4,923.98 MB
- 평균 지연시간: 12.80 ms
- 최대 지연시간: 1061.60 ms
- 최소 지연시간: 0.01 ms
- 대역폭: 20.63 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 12.80 ms)
- P50: 8.29ms, P95: 95.57ms, P99: 130.12ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 172 ops, 55.68 MB, 36.33 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.48 ms avg
- readMany: 304 ops, 2.05 MB, 20.26 ms avg

---

## 성능 분석

### 1. 토큰 생성 속도 (Tokens/s)

워커 수에 따른 토큰 생성 속도 변화:

```
2대: 0.39 tokens/s
4대: 0.44 tokens/s (+12.8% 향상)
8대: 0.18 tokens/s (-53.8% 저하)
```

**분석:**
- 2대에서 4대로 증가 시 약 12.8% 성능 향상
- 4대에서 8대로 증가 시 약 59% 성능 저하
- **최적 워커 수: 4대**

### 2. 출력 토큰당 시간 (TPOT)

```
2대: 2423.55 ms/tok
4대: 2150.56 ms/tok (-11.3% 개선)
8대: 5368.63 ms/tok (+149.5% 증가)
```

**분석:**
- 4대 구성이 가장 빠른 토큰 생성 속도
- 8대 구성에서 지연시간이 2배 이상 증가

### 3. 첫 토큰까지의 시간 (TTFT)

```
2대: 16.002 s
4대: 16.082 s (+0.5% 증가)
8대: 37.767 s (+135.9% 증가)
```

**분석:**
- 2대와 4대는 유사한 TTFT
- 8대에서 TTFT가 크게 증가 (2.4배)

### 4. 요청 완료 시간 (RCT)

```
2대: 309.349 s
4대: 275.581 s (-10.9% 개선)
8대: 687.061 s (+149.1% 증가)
```

**분석:**
- 4대 구성이 가장 빠른 완료 시간
- 8대 구성에서 완료 시간이 2배 이상 증가

### 5. 메모리 사용량

**Root 노드:**
- 2대: 12 GB
- 4대: 6.7 GB (-44%)
- 8대: 3.8 GB (-68%)

**Worker 노드:**
- 2대: 1 GB
- 4대: 5.9 GB (+490%)
- 8대: 3.0 GB (+200%)

**분석:**
- 워커 수가 증가할수록 Root 노드의 메모리 부담 감소
- 워커 노드의 메모리 사용량은 4대에서 최대치

### 6. 네트워크 성능

**총 전송량:**
- 2대: 1,227.59 MB
- 4대: 2,461.67 MB (+100%)
- 8대: 4,923.98 MB (+300%)

**평균 지연시간:**
- 2대: 3.66 ms
- 4대: 5.16 ms (+41%)
- 8대: 12.80 ms (+250%)

**대역폭:**
- 2대: 14.19 Mbps
- 4대: 80.43 Mbps (+467%)
- 8대: 20.63 Mbps (-74% from 4대)

**분석:**
- 워커 수 증가에 따라 네트워크 트래픽이 선형적으로 증가
- 4대에서 최대 대역폭 사용
- 8대에서 평균 지연시간이 크게 증가하며 병목 발생

### 7. 네트워크 작업 분석

**SYNC_NODE_SLICES (노드 슬라이스 동기화):**
- 2대: 382 ops, 30.92 MB, 2.01 ms avg
- 4대: 274 ops, 44.35 MB, 11.88 ms avg
- 8대: 172 ops, 55.68 MB, 36.33 ms avg

**분석:**
- 워커 수가 증가할수록 작업 수는 감소하지만 평균 지연시간이 크게 증가
- 8대 구성에서 평균 지연시간이 18배 증가 (2.01ms → 36.33ms)

**readMany:**
- 2대: 94 ops, 0.63 MB, 7.75 ms avg
- 4대: 202 ops, 1.36 MB, 15.72 ms avg
- 8대: 304 ops, 2.05 MB, 20.26 ms avg

**분석:**
- 워커 수 증가에 따라 작업 수와 전송량이 증가
- 평균 지연시간도 증가하지만 상대적으로 완만한 증가

---

## 결론 및 권장사항

### 주요 발견사항

1. **최적 워커 수: 4대**
   - 가장 높은 토큰 생성 속도 (0.44 tokens/s)
   - 가장 빠른 출력 토큰당 시간 (2150.56 ms)
   - 가장 빠른 요청 완료 시간 (275.581 s)

2. **8대 구성의 성능 저하 원인**
   - 네트워크 병목: 평균 지연시간이 12.80ms로 크게 증가
   - SYNC_NODE_SLICES 작업의 평균 지연시간이 36.33ms로 급증
   - 대역폭 효율 저하 (4대 대비 74% 감소)

3. **메모리 분산 효과**
   - 워커 수 증가에 따라 Root 노드 메모리 부담 감소
   - 4대 구성에서 워커 노드 메모리 사용량이 최대

4. **네트워크 병목 지표**
   - 모든 구성에서 높은 지연시간 분산 (P95 >> P50)
   - 네트워크 혼잡 가능성 존재

### 권장사항

1. **프로덕션 환경: 4대 워커 구성 권장**
   - 최적의 성능/비용 비율
   - 안정적인 네트워크 성능

2. **네트워크 최적화 필요**
   - 모든 구성에서 높은 지연시간 분산 발견
   - 네트워크 혼잡 완화 방안 검토 필요
   - 대역폭 최적화 및 동기화 전략 개선 고려

3. **8대 이상 구성 시 주의**
   - 현재 네트워크 인프라로는 성능 저하 발생
   - 고속 네트워크 인프라 구축 필요
   - 동기화 알고리즘 최적화 필요

4. **모니터링 지표**
   - SYNC_NODE_SLICES 지연시간 모니터링
   - 네트워크 대역폭 사용률 추적
   - P95, P99 지연시간 추적

---

## 부록: 테스트 명령어

### 2대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999
```

### 4대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999
```

### 8대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999 \
          100.68.147.68:9999 100.76.242.90:9999 100.77.7.70:9999
```

---

**문서 생성일:** 2024년
**테스트 모델:** Llama-30B Q40
**테스트 환경:** Raspberry Pi 클러스터

