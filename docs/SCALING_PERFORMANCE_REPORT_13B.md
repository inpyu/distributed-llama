# 분산 LLM 스케일링 성능 측정 보고서 (Llama-13B)

## 개요

본 문서는 dllama 분산 추론 시스템의 워커 노드 수에 따른 성능 측정 결과를 정리한 보고서입니다.

**테스트 환경:**
- 모델: `dllama_model_llama-13b_q40.m`
- 토크나이저: `dllama_tokenizer_llama2_13b.t`
- 버퍼 타입: `q80`
- 프롬프트: "Hello world"
- 최대 스텝: 128
- 스레드 수: 4

## 측정 결과 요약

| 워커 수 | Root 메모리 | Worker 메모리 | Tokens/s | TPOT (ms) | TTFT (s) | RCT (s) |
|---------|-------------|---------------|----------|-----------|----------|---------|
| 2대     | 7.3 GB      | 6.7 GB        | 0.80     | 1195.59   | 7.669    | 152.345 |
| 4대     | -           | -             | 0.83     | 1144.68   | 7.714    | 146.178 |
| 8대     | -           | -             | 0.31     | 3084.23   | 20.878   | 393.628 |

**주요 지표 설명:**
- **Tokens/s**: 초당 생성 토큰 수
- **TPOT**: Time Per Output Token (출력 토큰당 시간, 밀리초)
- **TTFT**: Time To First Token (첫 토큰까지의 시간, 초)
- **RCT**: Request Completion Time (요청 완료 시간, 초)

## 상세 측정 결과

### 1. 2대 워커 구성

**메모리 사용량:**
- Root: 7,338 MB (약 7.3 GB)
- Worker: 6,713 MB (약 6.7 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.93 (1079.92 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.84 (1194.23 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.80
- TPOT_MS: 1195.59
- TTFT_S: 7.669
- RCT_S: 152.345

**네트워크 성능:**
- 총 작업 수: 52,352
- 총 전송량: 675.04 MB
- 평균 지연시간: 3.13 ms
- 최대 지연시간: 228.85 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 52.12 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 3.13 ms)
- P50: 0.00ms, P95: 9.36ms, P99: 11.43ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 382 ops, 23.78 MB, 1.98 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 1.56 ms avg
- readMany: 94 ops, 0.49 MB, 7.78 ms avg

---

### 2. 4대 워커 구성

**메모리 사용량:**
- Root: 측정 데이터 없음
- Worker: 측정 데이터 없음

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.92 (1087.24 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.88 (1142.27 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.83
- TPOT_MS: 1144.68
- TTFT_S: 7.714
- RCT_S: 146.178

**네트워크 성능:**
- 총 작업 수: 73,088
- 총 전송량: 1,309.80 MB
- 평균 지연시간: 4.57 ms
- 최대 지연시간: 318.15 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 45.62 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 4.57 ms)
- P50: 0.03ms, P95: 102.91ms, P99: 103.03ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 274 ops, 34.12 MB, 7.96 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 0.04 ms avg
- readMany: 202 ops, 1.05 MB, 10.65 ms avg

---

### 3. 8대 워커 구성

**메모리 사용량:**
- Root: 측정 데이터 없음
- Worker: 측정 데이터 없음

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.35 (2891.33 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.32 (3081.63 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.31
- TPOT_MS: 3084.23
- TTFT_S: 20.878
- RCT_S: 393.628

**네트워크 성능:**
- 총 작업 수: 114,560
- 총 전송량: 2,573.48 MB
- 평균 지연시간: 10.57 ms
- 최대 지연시간: 331.90 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 52.25 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 10.57 ms)
- P50: 0.19ms, P95: 84.46ms, P99: 97.45ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 173 ops, 43.08 MB, 26.70 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 0.05 ms avg
- readMany: 303 ops, 1.57 MB, 14.97 ms avg

---

## 성능 분석

### 1. 토큰 생성 속도 (Tokens/s)

워커 수에 따른 토큰 생성 속도 변화:

```
2대: 0.80 tokens/s
4대: 0.83 tokens/s (+3.8% 향상)
8대: 0.31 tokens/s (-61.3% 저하)
```

**분석:**
- 2대에서 4대로 증가 시 약 3.8% 성능 향상
- 4대에서 8대로 증가 시 약 62.6% 성능 저하
- **최적 워커 수: 4대**

### 2. 출력 토큰당 시간 (TPOT)

```
2대: 1195.59 ms/tok
4대: 1144.68 ms/tok (-4.3% 개선)
8대: 3084.23 ms/tok (+169.5% 증가)
```

**분석:**
- 4대 구성이 가장 빠른 토큰 생성 속도
- 8대 구성에서 지연시간이 2.6배 증가
- 30B 모델 대비 절반 수준의 TPOT (더 빠른 추론)

### 3. 첫 토큰까지의 시간 (TTFT)

```
2대: 7.669 s
4대: 7.714 s (+0.6% 증가)
8대: 20.878 s (+172.2% 증가)
```

**분석:**
- 2대와 4대는 유사한 TTFT (약 7.7초)
- 8대에서 TTFT가 크게 증가 (2.7배)
- 30B 모델 대비 절반 수준의 TTFT (더 빠른 첫 토큰 생성)

### 4. 요청 완료 시간 (RCT)

```
2대: 152.345 s
4대: 146.178 s (-4.0% 개선)
8대: 393.628 s (+169.1% 증가)
```

**분석:**
- 4대 구성이 가장 빠른 완료 시간
- 8대 구성에서 완료 시간이 2.7배 증가
- 30B 모델 대비 절반 수준의 RCT (더 빠른 완료)

### 5. 메모리 사용량

**Root 노드:**
- 2대: 7.3 GB
- 4대: 측정 데이터 없음
- 8대: 측정 데이터 없음

**Worker 노드:**
- 2대: 6.7 GB
- 4대: 측정 데이터 없음
- 8대: 측정 데이터 없음

**분석:**
- 13B 모델은 30B 모델 대비 약 절반 수준의 메모리 사용량
- 2대 구성에서 Root와 Worker의 메모리 사용량이 유사 (7.3GB vs 6.7GB)

### 6. 네트워크 성능

**총 전송량:**
- 2대: 675.04 MB
- 4대: 1,309.80 MB (+94%)
- 8대: 2,573.48 MB (+281%)

**평균 지연시간:**
- 2대: 3.13 ms
- 4대: 4.57 ms (+46%)
- 8대: 10.57 ms (+238%)

**대역폭:**
- 2대: 52.12 Mbps
- 4대: 45.62 Mbps (-12.5%)
- 8대: 52.25 Mbps (+14.5% from 4대)

**분석:**
- 워커 수 증가에 따라 네트워크 트래픽이 선형적으로 증가
- 2대와 8대에서 유사한 대역폭 사용 (약 52 Mbps)
- 4대에서 대역폭 효율이 다소 저하
- 30B 모델 대비 절반 수준의 네트워크 트래픽

### 7. 네트워크 작업 분석

**SYNC_NODE_SLICES (노드 슬라이스 동기화):**
- 2대: 382 ops, 23.78 MB, 1.98 ms avg
- 4대: 274 ops, 34.12 MB, 7.96 ms avg
- 8대: 173 ops, 43.08 MB, 26.70 ms avg

**분석:**
- 워커 수가 증가할수록 작업 수는 감소하지만 평균 지연시간이 크게 증가
- 8대 구성에서 평균 지연시간이 13.5배 증가 (1.98ms → 26.70ms)
- 30B 모델 대비 절반 수준의 전송량

**readMany:**
- 2대: 94 ops, 0.49 MB, 7.78 ms avg
- 4대: 202 ops, 1.05 MB, 10.65 ms avg
- 8대: 303 ops, 1.57 MB, 14.97 ms avg

**분석:**
- 워커 수 증가에 따라 작업 수와 전송량이 증가
- 평균 지연시간도 증가하지만 상대적으로 완만한 증가
- 30B 모델 대비 절반 수준의 전송량

---

## 13B vs 30B 모델 비교

### 성능 비교

| 지표 | 13B (4대) | 30B (4대) | 차이 |
|------|-----------|-----------|------|
| Tokens/s | 0.83 | 0.44 | +88.6% |
| TPOT (ms) | 1144.68 | 2150.56 | -46.8% |
| TTFT (s) | 7.714 | 16.082 | -52.0% |
| RCT (s) | 146.178 | 275.581 | -47.0% |

**분석:**
- 13B 모델이 30B 모델 대비 약 2배 빠른 성능
- 모든 지표에서 13B 모델이 우수한 성능을 보임

### 메모리 비교

| 구성 | 13B Root | 30B Root | 13B Worker | 30B Worker |
|------|----------|----------|------------|------------|
| 2대 | 7.3 GB | 12 GB | 6.7 GB | 1 GB |
| 4대 | - | 6.7 GB | - | 5.9 GB |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 메모리 사용
- 2대 구성에서 13B는 Root와 Worker의 메모리 사용량이 유사

### 네트워크 비교 (4대 구성)

| 지표 | 13B | 30B | 차이 |
|------|-----|-----|------|
| 총 전송량 | 1,309.80 MB | 2,461.67 MB | -46.8% |
| 평균 지연시간 | 4.57 ms | 5.16 ms | -11.4% |
| 대역폭 | 45.62 Mbps | 80.43 Mbps | -43.3% |

**분석:**
- 13B 모델이 30B 모델 대비 절반 수준의 네트워크 트래픽
- 평균 지연시간은 유사하지만 대역폭 사용량이 절반 수준

---

## 결론 및 권장사항

### 주요 발견사항

1. **최적 워커 수: 4대**
   - 가장 높은 토큰 생성 속도 (0.83 tokens/s)
   - 가장 빠른 출력 토큰당 시간 (1144.68 ms)
   - 가장 빠른 요청 완료 시간 (146.178 s)

2. **8대 구성의 성능 저하 원인**
   - 네트워크 병목: 평균 지연시간이 10.57ms로 크게 증가
   - SYNC_NODE_SLICES 작업의 평균 지연시간이 26.70ms로 급증
   - 토큰 생성 속도가 62.6% 저하

3. **13B 모델의 장점**
   - 30B 모델 대비 약 2배 빠른 추론 속도
   - 절반 수준의 메모리 사용량
   - 절반 수준의 네트워크 트래픽

4. **네트워크 병목 지표**
   - 모든 구성에서 높은 지연시간 분산 (P95 >> P50)
   - 네트워크 혼잡 가능성 존재
   - 4대 구성에서 P95 지연시간이 102.91ms로 높음

### 권장사항

1. **프로덕션 환경: 4대 워커 구성 권장**
   - 최적의 성능/비용 비율
   - 2대 대비 약 3.8% 성능 향상
   - 안정적인 네트워크 성능

2. **13B 모델 선택 기준**
   - 더 빠른 추론 속도가 필요한 경우
   - 메모리 제약이 있는 환경
   - 네트워크 대역폭이 제한적인 환경

3. **네트워크 최적화 필요**
   - 모든 구성에서 높은 지연시간 분산 발견
   - 특히 4대 구성에서 P95 지연시간이 102.91ms로 높음
   - 네트워크 혼잡 완화 방안 검토 필요
   - 대역폭 최적화 및 동기화 전략 개선 고려

4. **8대 이상 구성 시 주의**
   - 현재 네트워크 인프라로는 성능 저하 발생
   - 토큰 생성 속도가 62.6% 저하
   - 고속 네트워크 인프라 구축 필요
   - 동기화 알고리즘 최적화 필요

5. **모니터링 지표**
   - SYNC_NODE_SLICES 지연시간 모니터링
   - 네트워크 대역폭 사용률 추적
   - P95, P99 지연시간 추적

---

## 부록: 테스트 명령어

### 2대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999
```

### 4대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999
```

### 8대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999 \
          100.68.147.68:9999 100.76.242.90:9999 100.77.7.70:9999
```

---

**문서 생성일:** 2024년
**테스트 모델:** Llama-13B Q40
**테스트 환경:** Raspberry Pi 클러스터



