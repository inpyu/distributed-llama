# 분산 LLM 스케일링 성능 측정 통합 보고서 (Llama-13B vs 30B)

## 개요

본 문서는 dllama 분산 추론 시스템의 워커 노드 수에 따른 성능 측정 결과를 정리한 통합 보고서입니다. Llama-13B와 Llama-30B 모델의 성능을 비교 분석합니다.

**테스트 환경:**
- 모델: `dllama_model_llama-13b_q40.m`, `dllama_model_llama-30b_q40.m`
- 토크나이저: `dllama_tokenizer_llama2_13b.t`, `dllama_tokenizer_llama2.t`
- 버퍼 타입: `q80`
- 프롬프트: "Hello world"
- 최대 스텝: 128
- 스레드 수: 4

## 측정 결과 통합 요약

### Llama-13B 모델

| 워커 수 | Root 메모리 | Worker 메모리 | Tokens/s | TPOT (ms) | TTFT (s) | RCT (s) |
|---------|-------------|---------------|----------|-----------|----------|---------|
| 2대     | 7.3 GB      | 6.7 GB        | 0.80     | 1195.59   | 7.669    | 152.345 |
| 4대     | -           | -             | 0.83     | 1144.68   | 7.714    | 146.178 |
| 8대     | -           | -             | 0.31     | 3084.23   | 20.878   | 393.628 |

### Llama-30B 모델

| 워커 수 | Root 메모리 | Worker 메모리 | Tokens/s | TPOT (ms) | TTFT (s) | RCT (s) |
|---------|-------------|---------------|----------|-----------|----------|---------|
| 2대     | 12 GB       | 1 GB          | 0.39     | 2423.55   | 16.002   | 309.349 |
| 4대     | 6.7 GB      | 5.9 GB        | 0.44     | 2150.56   | 16.082   | 275.581 |
| 8대     | 3.8 GB      | 3.0 GB        | 0.18     | 5368.63   | 37.767   | 687.061 |

**주요 지표 설명:**
- **Tokens/s**: 초당 생성 토큰 수
- **TPOT**: Time Per Output Token (출력 토큰당 시간, 밀리초)
- **TTFT**: Time To First Token (첫 토큰까지의 시간, 초)
- **RCT**: Request Completion Time (요청 완료 시간, 초)

## 모델 간 성능 비교

### 1. 토큰 생성 속도 비교 (Tokens/s)

| 워커 수 | 13B | 30B | 차이 | 개선율 |
|---------|-----|-----|------|--------|
| 2대     | 0.80 | 0.39 | +0.41 | +105.1% |
| 4대     | 0.83 | 0.44 | +0.39 | +88.6% |
| 8대     | 0.31 | 0.18 | +0.13 | +72.2% |

**분석:**
- 모든 워커 구성에서 13B 모델이 30B 모델 대비 약 2배 빠른 토큰 생성 속도
- 4대 구성에서 13B가 가장 우수한 성능 (0.83 tokens/s)
- 8대 구성에서도 13B가 상대적으로 더 나은 성능 유지

### 2. 출력 토큰당 시간 비교 (TPOT)

| 워커 수 | 13B (ms) | 30B (ms) | 차이 | 개선율 |
|---------|----------|----------|------|--------|
| 2대     | 1195.59  | 2423.55  | -1227.96 | -50.7% |
| 4대     | 1144.68  | 2150.56  | -1005.88 | -46.8% |
| 8대     | 3084.23  | 5368.63  | -2284.40 | -42.6% |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 TPOT
- 4대 구성에서 가장 빠른 토큰 생성 (13B: 1144.68ms, 30B: 2150.56ms)
- 8대 구성에서도 13B가 상대적으로 더 나은 성능

### 3. 첫 토큰까지의 시간 비교 (TTFT)

| 워커 수 | 13B (s) | 30B (s) | 차이 | 개선율 |
|---------|---------|---------|------|--------|
| 2대     | 7.669   | 16.002  | -8.333 | -52.0% |
| 4대     | 7.714   | 16.082  | -8.368 | -52.0% |
| 8대     | 20.878  | 37.767  | -16.889 | -44.7% |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 TTFT
- 2대와 4대 구성에서 유사한 TTFT (약 7.7초)
- 8대 구성에서 두 모델 모두 TTFT가 크게 증가하지만 13B가 상대적으로 더 나음

### 4. 요청 완료 시간 비교 (RCT)

| 워커 수 | 13B (s) | 30B (s) | 차이 | 개선율 |
|---------|---------|---------|------|--------|
| 2대     | 152.345 | 309.349 | -157.004 | -50.7% |
| 4대     | 146.178 | 275.581 | -129.403 | -47.0% |
| 8대     | 393.628 | 687.061 | -293.433 | -42.7% |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 RCT
- 4대 구성에서 가장 빠른 완료 시간 (13B: 146.178s, 30B: 275.581s)
- 8대 구성에서 두 모델 모두 RCT가 크게 증가하지만 13B가 상대적으로 더 나음

### 5. 메모리 사용량 비교

| 구성 | 13B Root | 30B Root | 13B Worker | 30B Worker |
|------|----------|----------|------------|------------|
| 2대  | 7.3 GB   | 12 GB    | 6.7 GB     | 1 GB       |
| 4대  | -        | 6.7 GB   | -          | 5.9 GB     |
| 8대  | -        | 3.8 GB   | -          | 3.0 GB     |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 메모리 사용량
- 2대 구성에서 13B는 Root와 Worker의 메모리 사용량이 유사 (7.3GB vs 6.7GB)
- 30B 모델은 워커 수 증가에 따라 Root 노드 메모리 부담이 크게 감소

### 6. 네트워크 성능 비교

#### 총 전송량

| 워커 수 | 13B (MB) | 30B (MB) | 차이 | 비율 |
|---------|----------|----------|------|------|
| 2대     | 675.04   | 1,227.59 | -552.55 | 55.0% |
| 4대     | 1,309.80 | 2,461.67 | -1,151.87 | 53.2% |
| 8대     | 2,573.48 | 4,923.98 | -2,350.50 | 52.3% |

**분석:**
- 13B 모델이 30B 모델 대비 약 절반 수준의 네트워크 트래픽
- 워커 수 증가에 따라 두 모델 모두 선형적으로 트래픽 증가

#### 평균 지연시간

| 워커 수 | 13B (ms) | 30B (ms) | 차이 |
|---------|----------|----------|------|
| 2대     | 3.13     | 3.66     | -0.53 |
| 4대     | 4.57     | 5.16     | -0.59 |
| 8대     | 10.57    | 12.80    | -2.23 |

**분석:**
- 13B 모델이 30B 모델 대비 약간 낮은 평균 지연시간
- 8대 구성에서 두 모델 모두 지연시간이 크게 증가

#### 대역폭

| 워커 수 | 13B (Mbps) | 30B (Mbps) | 차이 |
|---------|------------|------------|------|
| 2대     | 52.12      | 14.19      | +37.93 |
| 4대     | 45.62      | 80.43      | -34.81 |
| 8대     | 52.25      | 20.63      | +31.62 |

**분석:**
- 대역폭 사용 패턴이 모델과 워커 수에 따라 다름
- 4대 구성에서 30B가 더 높은 대역폭 사용 (80.43 Mbps)
- 2대와 8대 구성에서 13B가 더 높은 대역폭 사용

## 워커 수별 성능 분석

### 2대 워커 구성

**성능 비교:**
- **13B**: 0.80 tokens/s, TPOT 1195.59ms, TTFT 7.669s, RCT 152.345s
- **30B**: 0.39 tokens/s, TPOT 2423.55ms, TTFT 16.002s, RCT 309.349s
- **13B 우위**: 모든 지표에서 13B가 약 2배 빠름

**메모리:**
- **13B**: Root 7.3GB, Worker 6.7GB (균등 분산)
- **30B**: Root 12GB, Worker 1GB (Root 집중)

**네트워크:**
- **13B**: 675.04 MB, 3.13ms 평균 지연, 52.12 Mbps
- **30B**: 1,227.59 MB, 3.66ms 평균 지연, 14.19 Mbps

**결론:** 2대 구성에서는 13B 모델이 모든 면에서 우수한 성능을 보임

### 4대 워커 구성 (최적 구성)

**성능 비교:**
- **13B**: 0.83 tokens/s, TPOT 1144.68ms, TTFT 7.714s, RCT 146.178s
- **30B**: 0.44 tokens/s, TPOT 2150.56ms, TTFT 16.082s, RCT 275.581s
- **13B 우위**: 모든 지표에서 13B가 약 2배 빠름

**메모리:**
- **13B**: 측정 데이터 없음
- **30B**: Root 6.7GB, Worker 5.9GB (균등 분산)

**네트워크:**
- **13B**: 1,309.80 MB, 4.57ms 평균 지연, 45.62 Mbps
- **30B**: 2,461.67 MB, 5.16ms 평균 지연, 80.43 Mbps

**결론:** 4대 구성은 두 모델 모두에서 최적의 성능을 보이는 구성

### 8대 워커 구성

**성능 비교:**
- **13B**: 0.31 tokens/s, TPOT 3084.23ms, TTFT 20.878s, RCT 393.628s
- **30B**: 0.18 tokens/s, TPOT 5368.63ms, TTFT 37.767s, RCT 687.061s
- **13B 우위**: 모든 지표에서 13B가 상대적으로 더 나은 성능

**메모리:**
- **13B**: 측정 데이터 없음
- **30B**: Root 3.8GB, Worker 3.0GB (균등 분산)

**네트워크:**
- **13B**: 2,573.48 MB, 10.57ms 평균 지연, 52.25 Mbps
- **30B**: 4,923.98 MB, 12.80ms 평균 지연, 20.63 Mbps

**결론:** 8대 구성에서는 두 모델 모두 성능 저하가 발생하지만, 13B가 상대적으로 더 나은 성능 유지

## 스케일링 패턴 분석

### 토큰 생성 속도 스케일링

**13B 모델:**
```
2대 → 4대: +3.8% 향상
4대 → 8대: -62.6% 저하
```

**30B 모델:**
```
2대 → 4대: +12.8% 향상
4대 → 8대: -59.1% 저하
```

**분석:**
- 두 모델 모두 4대에서 최적 성능
- 8대에서 성능 저하가 발생하지만, 30B가 더 큰 저하율
- 30B 모델이 2대→4대 스케일링에서 더 큰 성능 향상

### 네트워크 트래픽 스케일링

**13B 모델:**
```
2대 → 4대: +94% 증가
4대 → 8대: +96% 증가
```

**30B 모델:**
```
2대 → 4대: +100% 증가
4대 → 8대: +100% 증가
```

**분석:**
- 두 모델 모두 워커 수 증가에 따라 선형적으로 트래픽 증가
- 13B 모델이 절대값은 작지만 증가율은 유사

### 지연시간 스케일링

**13B 모델:**
```
2대 → 4대: +46% 증가
4대 → 8대: +131% 증가
```

**30B 모델:**
```
2대 → 4대: +41% 증가
4대 → 8대: +148% 증가
```

**분석:**
- 두 모델 모두 8대 구성에서 지연시간이 크게 증가
- 30B 모델이 8대 구성에서 더 큰 지연시간 증가

## 상세 측정 결과

### Llama-13B 모델 상세 결과

#### 1. 2대 워커 구성

**메모리 사용량:**
- Root: 7,338 MB (약 7.3 GB)
- Worker: 6,713 MB (약 6.7 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.93 (1079.92 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.84 (1194.23 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.80
- TPOT_MS: 1195.59
- TTFT_S: 7.669
- RCT_S: 152.345

**네트워크 성능:**
- 총 작업 수: 52,352
- 총 전송량: 675.04 MB
- 평균 지연시간: 3.13 ms
- 최대 지연시간: 228.85 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 52.12 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 3.13 ms)
- P50: 0.00ms, P95: 9.36ms, P99: 11.43ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 382 ops, 23.78 MB, 1.98 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 1.56 ms avg
- readMany: 94 ops, 0.49 MB, 7.78 ms avg

#### 2. 4대 워커 구성

**메모리 사용량:**
- Root: 측정 데이터 없음
- Worker: 측정 데이터 없음

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.92 (1087.24 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.88 (1142.27 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.83
- TPOT_MS: 1144.68
- TTFT_S: 7.714
- RCT_S: 146.178

**네트워크 성능:**
- 총 작업 수: 73,088
- 총 전송량: 1,309.80 MB
- 평균 지연시간: 4.57 ms
- 최대 지연시간: 318.15 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 45.62 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 4.57 ms)
- P50: 0.03ms, P95: 102.91ms, P99: 103.03ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 274 ops, 34.12 MB, 7.96 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 0.04 ms avg
- readMany: 202 ops, 1.05 MB, 10.65 ms avg

#### 3. 8대 워커 구성

**메모리 사용량:**
- Root: 측정 데이터 없음
- Worker: 측정 데이터 없음

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.35 (2891.33 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.32 (3081.63 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.31
- TPOT_MS: 3084.23
- TTFT_S: 20.878
- RCT_S: 393.628

**네트워크 성능:**
- 총 작업 수: 114,560
- 총 전송량: 2,573.48 MB
- 평균 지연시간: 10.57 ms
- 최대 지연시간: 331.90 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 52.25 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 10.57 ms)
- P50: 0.19ms, P95: 84.46ms, P99: 97.45ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 173 ops, 43.08 MB, 26.70 ms avg
- SYNC_WITH_ROOT: 24 ops, 2.81 MB, 0.05 ms avg
- readMany: 303 ops, 1.57 MB, 14.97 ms avg

### Llama-30B 모델 상세 결과

#### 1. 2대 워커 구성

**메모리 사용량:**
- Root: 12 GB
- Worker: 1 GB

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.44 (2278.38 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.41 (2421.65 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.39
- TPOT_MS: 2423.55
- TTFT_S: 16.002
- RCT_S: 309.349

**네트워크 성능:**
- 총 작업 수: 77,952
- 총 전송량: 1,227.59 MB
- 평균 지연시간: 3.66 ms
- 최대 지연시간: 228.62 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 14.19 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 3.66 ms)
- P50: 0.01ms, P95: 9.01ms, P99: 11.52ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 382 ops, 30.92 MB, 2.01 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.49 ms avg
- readMany: 94 ops, 0.63 MB, 7.75 ms avg

#### 2. 4대 워커 구성

**메모리 사용량:**
- Root: 6,739 MB (약 6.7 GB)
- Worker: 5,926 MB (약 5.9 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.45 (2201.39 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.47 (2148.05 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.44
- TPOT_MS: 2150.56
- TTFT_S: 16.082
- RCT_S: 275.581

**네트워크 성능:**
- 총 작업 수: 108,928
- 총 전송량: 2,461.67 MB
- 평균 지연시간: 5.16 ms
- 최대 지연시간: 421.25 ms
- 최소 지연시간: 0.00 ms
- 대역폭: 80.43 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 5.16 ms)
- P50: 0.08ms, P95: 26.21ms, P99: 31.59ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 274 ops, 44.35 MB, 11.88 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.56 ms avg
- readMany: 202 ops, 1.36 MB, 15.72 ms avg

#### 3. 8대 워커 구성

**메모리 사용량:**
- Root: 3,782 MB (약 3.8 GB)
- Worker: 2,970 MB (약 3.0 GB)

**성능 지표:**
```
Evaluation
   nBatches: 32
    nTokens: 6
   tokens/s: 0.19 (5347.35 ms/tok)

Prediction
    nTokens: 122
   tokens/s: 0.19 (5365.57 ms/tok)
```

**메트릭:**
- InputTokens: 7
- OutputTokens: 122
- TokensPerSecond: 0.18
- TPOT_MS: 5368.63
- TTFT_S: 37.767
- RCT_S: 687.061

**네트워크 성능:**
- 총 작업 수: 170,880
- 총 전송량: 4,923.98 MB
- 평균 지연시간: 12.80 ms
- 최대 지연시간: 1061.60 ms
- 최소 지연시간: 0.01 ms
- 대역폭: 20.63 Mbps

**네트워크 병목 분석:**
- 가장 느린 소켓: 0 (평균 지연시간: 12.80 ms)
- P50: 8.29ms, P95: 95.57ms, P99: 130.12ms
- ⚠️ 높은 지연시간 분산 (P95 >> P50) - 잠재적 네트워크 혼잡

**작업 분석:**
- SYNC_NODE_SLICES: 172 ops, 55.68 MB, 36.33 ms avg
- SYNC_WITH_ROOT: 24 ops, 3.66 MB, 1.48 ms avg
- readMany: 304 ops, 2.05 MB, 20.26 ms avg

## 통합 결론 및 권장사항

### 주요 발견사항

1. **최적 워커 수: 4대 (두 모델 공통)**
   - **13B**: 0.83 tokens/s, TPOT 1144.68ms, RCT 146.178s
   - **30B**: 0.44 tokens/s, TPOT 2150.56ms, RCT 275.581s
   - 두 모델 모두 4대 구성에서 최적 성능

2. **13B 모델의 우수성**
   - 모든 워커 구성에서 30B 대비 약 2배 빠른 성능
   - 절반 수준의 메모리 사용량
   - 절반 수준의 네트워크 트래픽
   - 더 빠른 TTFT (약 7.7초 vs 16초)

3. **8대 구성의 성능 저하 (두 모델 공통)**
   - **13B**: 62.6% 성능 저하 (0.83 → 0.31 tokens/s)
   - **30B**: 59.1% 성능 저하 (0.44 → 0.18 tokens/s)
   - 네트워크 병목으로 인한 성능 저하
   - SYNC_NODE_SLICES 지연시간 급증

4. **메모리 분산 패턴 차이**
   - **13B**: 2대 구성에서 Root와 Worker 메모리 균등 분산
   - **30B**: 2대 구성에서 Root 집중, 워커 수 증가 시 균등 분산

5. **네트워크 병목 지표**
   - 모든 구성에서 높은 지연시간 분산 (P95 >> P50)
   - 네트워크 혼잡 가능성 존재
   - 13B 4대 구성에서 P95 지연시간이 102.91ms로 특히 높음

### 모델 선택 가이드

#### Llama-13B 모델 선택 시나리오

**권장 상황:**
- ✅ 더 빠른 추론 속도가 필요한 경우
- ✅ 메모리 제약이 있는 환경
- ✅ 네트워크 대역폭이 제한적인 환경
- ✅ 낮은 지연시간이 중요한 실시간 애플리케이션
- ✅ 비용 효율적인 운영이 필요한 경우

**성능 특성:**
- 약 2배 빠른 토큰 생성 속도
- 절반 수준의 메모리 및 네트워크 사용
- 더 빠른 첫 토큰 생성 (TTFT)

#### Llama-30B 모델 선택 시나리오

**권장 상황:**
- ✅ 더 큰 모델의 성능이 필요한 경우
- ✅ 메모리 여유가 있는 환경
- ✅ 네트워크 대역폭이 충분한 환경
- ✅ 모델 크기로 인한 품질 향상이 중요한 경우

**성능 특성:**
- 더 큰 모델 파라미터로 인한 잠재적 품질 향상
- 더 많은 메모리 및 네트워크 리소스 필요
- 상대적으로 느린 추론 속도

### 워커 구성 권장사항

#### 2대 워커 구성

**권장 모델:** 13B
- 13B: 0.80 tokens/s, 메모리 균등 분산
- 30B: 0.39 tokens/s, Root 메모리 집중

**적용 시나리오:**
- 제한된 하드웨어 리소스
- 소규모 배포
- 테스트 환경

#### 4대 워커 구성 (프로덕션 권장)

**권장 모델:** 두 모델 모두 적합
- **13B**: 0.83 tokens/s (최고 성능)
- **30B**: 0.44 tokens/s (최고 성능)

**적용 시나리오:**
- 프로덕션 환경
- 최적의 성능/비용 비율
- 안정적인 네트워크 성능

**특징:**
- 두 모델 모두 최적 성능
- 균등한 메모리 분산 (30B)
- 안정적인 네트워크 성능

#### 8대 워커 구성

**권장 모델:** 13B (상대적으로 더 나은 성능)
- **13B**: 0.31 tokens/s (4대 대비 62.6% 저하)
- **30B**: 0.18 tokens/s (4대 대비 59.1% 저하)

**적용 시나리오:**
- 고속 네트워크 인프라 구축 시
- 동기화 알고리즘 최적화 후
- 대규모 배포 (네트워크 최적화 필수)

**주의사항:**
- 현재 네트워크 인프라로는 성능 저하 발생
- 네트워크 병목 해결 필요
- SYNC_NODE_SLICES 최적화 필요

### 네트워크 최적화 권장사항

1. **네트워크 혼잡 완화**
   - 모든 구성에서 높은 지연시간 분산 발견
   - 네트워크 대역폭 모니터링 및 최적화
   - QoS 설정 고려

2. **동기화 전략 개선**
   - SYNC_NODE_SLICES 작업 최적화
   - 8대 구성에서 지연시간 급증 (13B: 26.70ms, 30B: 36.33ms)
   - 배치 처리 및 비동기 동기화 고려

3. **모니터링 지표**
   - SYNC_NODE_SLICES 지연시간 모니터링
   - 네트워크 대역폭 사용률 추적
   - P95, P99 지연시간 추적
   - 네트워크 혼잡 지표 모니터링

### 성능 최적화 체크리스트

#### 하드웨어
- [ ] 충분한 메모리 (13B: 7GB+, 30B: 12GB+)
- [ ] 고속 네트워크 인프라 (8대 구성 시 필수)
- [ ] CPU 스레드 최적화 (현재 4 스레드)

#### 소프트웨어
- [ ] 네트워크 동기화 알고리즘 최적화
- [ ] SYNC_NODE_SLICES 지연시간 개선
- [ ] 네트워크 혼잡 모니터링 및 대응

#### 구성
- [ ] 워커 수: 4대 권장 (프로덕션)
- [ ] 모델 선택: 용도에 따라 13B 또는 30B
- [ ] 메모리 분산 전략 수립

---

## 부록: 테스트 명령어

### Llama-13B 모델

#### 2대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999
```

#### 4대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999
```

#### 8대 워커
```bash
./dllama inference \
  --model dllama_model_llama-13b_q40.m \
  --tokenizer dllama_tokenizer_llama2_13b.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999 \
          100.68.147.68:9999 100.76.242.90:9999 100.77.7.70:9999
```

### Llama-30B 모델

#### 2대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999
```

#### 4대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999
```

#### 8대 워커
```bash
./dllama inference \
  --model dllama_model_llama-30b_q40.m \
  --tokenizer dllama_tokenizer_llama2.t \
  --buffer-float-type q80 \
  --prompt "Hello world" \
  --steps 128 \
  --nthreads 4 \
  --workers 100.67.190.3:9999 100.84.48.55:9999 100.76.95.128:9999 100.78.3.114:9999 \
          100.68.147.68:9999 100.76.242.90:9999 100.77.7.70:9999
```

---

**문서 생성일:** 2024년
**테스트 모델:** Llama-13B Q40, Llama-30B Q40
**테스트 환경:** Raspberry Pi 클러스터
**문서 버전:** 통합 비교 보고서 v1.0



